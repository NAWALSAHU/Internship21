{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae48ddcc",
   "metadata": {},
   "source": [
    "# WEB SCRAPING – ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c366e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Importing selenium webdriver\n",
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "15d4c005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\nawal'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b2d4bd",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 \n",
    "jobs data. \n",
    "This task will be done in following steps: \n",
    "1. First get the webpage https://www.naukri.com/ 2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the \n",
    "location” field. \n",
    "3. Then click the search button. \n",
    "4. Then scrape the data for the first 10 jobs results you get. \n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45fb801a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_required</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Tech Data Advanced Solutions India Pvt Ltd</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>Senior Business Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>(19 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru(Bellandur)</td>\n",
       "      <td>Data Analyst - Flipkart Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Flipkart</td>\n",
       "      <td></td>\n",
       "      <td>Business Data Analyst - Database Design/Mining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>(3788 Reviews)</td>\n",
       "      <td></td>\n",
       "      <td>Urgent Openings For Data Analyst / Business An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Business Data Analyst(BigId) - Capco - Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Data Analyst - Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience_required                                company_name  \\\n",
       "0             3-8 Yrs  Tech Data Advanced Solutions India Pvt Ltd   \n",
       "1             0-3 Yrs                                (19 Reviews)   \n",
       "2                                                        Flipkart   \n",
       "3                                                  (3788 Reviews)   \n",
       "4                                                                   \n",
       "5                                                                   \n",
       "6                                                                   \n",
       "7                                                                   \n",
       "8                                                                   \n",
       "9                                                                   \n",
       "\n",
       "                              job_location  \\\n",
       "0  Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "1           Bangalore/Bengaluru(Bellandur)   \n",
       "2                                            \n",
       "3                                            \n",
       "4                                            \n",
       "5                                            \n",
       "6                                            \n",
       "7                                            \n",
       "8                                            \n",
       "9                                            \n",
       "\n",
       "                                           job_title  \n",
       "0                       Senior Business Data Analyst  \n",
       "1                  Data Analyst - Flipkart Analytics  \n",
       "2     Business Data Analyst - Database Design/Mining  \n",
       "3  Urgent Openings For Data Analyst / Business An...  \n",
       "4                                       Data Analyst  \n",
       "5   Business Data Analyst(BigId) - Capco - Bangalore  \n",
       "6                                Senior Data Analyst  \n",
       "7                                       Data Analyst  \n",
       "8                           Data Analyst - Marketing  \n",
       "9                                       Data Analyst  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "\n",
    "# entering “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\") #job search bar\n",
    "search_field_location=driver.find_element_by_id('qsb-location-sugg') #location search bar\n",
    "search_field_designation.send_keys(\"Data Analyst\")\n",
    "search_field_location.send_keys(\"Bangalore\")\n",
    "\n",
    "\n",
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "# creating empty lists for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "\n",
    "#scraping the job-titles\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "\n",
    "time.sleep(4)\n",
    "#scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "        \n",
    "time.sleep(4)        \n",
    "#scraping the company_name \n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:2]\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "#scraping the experience_required \n",
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\"--\") \n",
    "    else:\n",
    "            experience_required.append(i.text)\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "# creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"experience_required\":experience_required[0:10],\"company_name\":company_name[0:10],\"job_location\":job_location[0:10],\n",
    "                \"job_title\":job_title[0:10]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cc305b",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data. \n",
    "This task will be done in following steps: \n",
    "1. First get the webpage https://www.naukri.com/ 2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the \n",
    "location” field. \n",
    "3. Then click the search button. \n",
    "4. Then scrape the data for the first 10 jobs results you get. \n",
    "5. Finally create a dataframe of the scraped data. \n",
    "No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c44666d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>(10540 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist | Fortune 500 Supermarke...</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td></td>\n",
       "      <td>Work Experience:\\n~2+ years of relevant experi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>(10540 Reviews)</td>\n",
       "      <td></td>\n",
       "      <td>Duties and Responsibilities\\nResearch and Deve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist- Data &amp; Analytics</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Interact with relevant teams to identify busin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Forecasting Analyst/ Data Scientist (US Client)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Roles and Responsibilities\\nThe person will be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Roles and Responsibilities\\nRapid business req...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Process Innovation Analyst - APAC/Data Scienti...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Dear Candidate,\\n\\nThis is to keep you posted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Duties and Responsibilities\\nResearch and Deve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Data Scientist @ Mobiotics\\n\\nRoles and Respon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title            company_name  \\\n",
       "0                              Senior Data Scientist  IBM India Pvt. Limited   \n",
       "1                 Data Scientist: Advanced Analytics         (10540 Reviews)   \n",
       "2  Senior Data Scientist | Fortune 500 Supermarke...  IBM India Pvt. Limited   \n",
       "3                              Senior Data Scientist         (10540 Reviews)   \n",
       "4            Senior Data Scientist- Data & Analytics                           \n",
       "5    Forecasting Analyst/ Data Scientist (US Client)                           \n",
       "6                                     Data Scientist                           \n",
       "7  Process Innovation Analyst - APAC/Data Scienti...                           \n",
       "8                                     Data Scientist                           \n",
       "9                                     Data Scientist                           \n",
       "\n",
       "          job_location                                    job_description  \n",
       "0  Bangalore/Bengaluru                                                ---  \n",
       "1  Bangalore/Bengaluru                                                ---  \n",
       "2                       Work Experience:\\n~2+ years of relevant experi...  \n",
       "3                       Duties and Responsibilities\\nResearch and Deve...  \n",
       "4                       Interact with relevant teams to identify busin...  \n",
       "5                       Roles and Responsibilities\\nThe person will be...  \n",
       "6                       Roles and Responsibilities\\nRapid business req...  \n",
       "7                       Dear Candidate,\\n\\nThis is to keep you posted ...  \n",
       "8                       Duties and Responsibilities\\nResearch and Deve...  \n",
       "9                       Data Scientist @ Mobiotics\\n\\nRoles and Respon...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "\n",
    "# entering “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")   #job search bar\n",
    "search_field_location=driver.find_element_by_id('qsb-location-sugg')  #location search bar\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "search_field_location.send_keys(\"Bangalore\")\n",
    "\n",
    "\n",
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "# creating empty lists for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "full_job_description=[]\n",
    "\n",
    "\n",
    "#scraping the job-titles\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "\n",
    "time.sleep(4)\n",
    "#scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "        \n",
    "time.sleep(4)        \n",
    "#scraping the company_name \n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "\n",
    "# scraping the full job-description, for scraping full job description we have to go in each of the jobs separately\n",
    "urls=[i.get_attribute(\"href\")for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")]\n",
    "for url in urls[0:10]:\n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        raw_description=driver.find_element_by_xpath(\"//section[@class='job-desc']/div[1]\").text\n",
    "        description=raw_description.replace(\"Contact Person\",\"@@@@@\")\n",
    "        description= description.split(\"@@@@@\")\n",
    "        full_job_description.append(description[0])\n",
    "    except NoSuchElementException :\n",
    "        full_job_description.append(\"---\")\n",
    "        \n",
    "        \n",
    " # creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"job_title\":job_title[0:10],\"company_name\":company_name[0:10],\"job_location\":job_location[0:10],\n",
    "                \"job_description\":full_job_description[0:10]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642bb306",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below: \n",
    "\n",
    "You have to use the location and salary filter. \n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results. \n",
    "You have to scrape the job-title, job-location, company name, experience required. \n",
    "The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs \n",
    "The task will be done as shown in the below steps: \n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field. \n",
    "3. Then click the search button. \n",
    "4. Then apply the location filter and salary filter by checking the respective boxes \n",
    "5. Then scrape the data for the first 10 jobs results you get. \n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5aa52491",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[2]/div[2]/div[2]/label/p\"}\n  (Session info: chrome=95.0.4638.69)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x008F0C43+2493507]\n\tOrdinal0 [0x0088A4B1+2073777]\n\tOrdinal0 [0x00792608+1058312]\n\tOrdinal0 [0x007BCAA4+1231524]\n\tOrdinal0 [0x007E6C62+1404002]\n\tOrdinal0 [0x007D597A+1333626]\n\tOrdinal0 [0x007E5038+1396792]\n\tOrdinal0 [0x007D580B+1333259]\n\tOrdinal0 [0x007B2314+1188628]\n\tOrdinal0 [0x007B316F+1192303]\n\tGetHandleVerifier [0x00A77BF6+1548950]\n\tGetHandleVerifier [0x00B2461C+2256060]\n\tGetHandleVerifier [0x0097C13B+518107]\n\tGetHandleVerifier [0x0097B1E0+514176]\n\tOrdinal0 [0x0088F53D+2094397]\n\tOrdinal0 [0x00893418+2110488]\n\tOrdinal0 [0x00893552+2110802]\n\tOrdinal0 [0x0089CE81+2150017]\n\tBaseThreadInitThunk [0x762BFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x76EE7A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x76EE7A6E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-7cfdc3cce456>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m#finding the delhi/ncr check box\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[2]/div[2]/div[2]/label/p\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    512\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         )\n\u001b[1;32m--> 514\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mWebElement\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m   1236\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1238\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m   1239\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    420\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[2]/div[2]/div[2]/label/p\"}\n  (Session info: chrome=95.0.4638.69)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x008F0C43+2493507]\n\tOrdinal0 [0x0088A4B1+2073777]\n\tOrdinal0 [0x00792608+1058312]\n\tOrdinal0 [0x007BCAA4+1231524]\n\tOrdinal0 [0x007E6C62+1404002]\n\tOrdinal0 [0x007D597A+1333626]\n\tOrdinal0 [0x007E5038+1396792]\n\tOrdinal0 [0x007D580B+1333259]\n\tOrdinal0 [0x007B2314+1188628]\n\tOrdinal0 [0x007B316F+1192303]\n\tGetHandleVerifier [0x00A77BF6+1548950]\n\tGetHandleVerifier [0x00B2461C+2256060]\n\tGetHandleVerifier [0x0097C13B+518107]\n\tGetHandleVerifier [0x0097B1E0+514176]\n\tOrdinal0 [0x0088F53D+2094397]\n\tOrdinal0 [0x00893418+2110488]\n\tOrdinal0 [0x00893552+2110802]\n\tOrdinal0 [0x0089CE81+2150017]\n\tBaseThreadInitThunk [0x762BFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x76EE7A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x76EE7A6E+238]\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "\n",
    "# entering “Data Scientist” in “Skill,Designations,Companies” field\n",
    "\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")   #job  search bar\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "# creating empty lists for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "#finding the delhi/ncr check box\n",
    "loc=driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[2]/div[2]/div[2]/label/p\")\n",
    "loc.click()\n",
    "\n",
    "time.sleep(2)\n",
    "# finding the salary check box\n",
    "slry_box = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[2]/label/p\")\n",
    "slry_box.click()\n",
    "\n",
    "time.sleep(3)\n",
    "#scraping the job-titles\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "        \n",
    "\n",
    "time.sleep(3)\n",
    "#scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "        \n",
    "\n",
    "time.sleep(3)\n",
    "#scraping the company_name \n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "        \n",
    "\n",
    "time.sleep(3)\n",
    "#scraping the experience_required \n",
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\"--\") \n",
    "    else:\n",
    "            experience_required.append(i.text)\n",
    "            \n",
    "time.sleep(3)            \n",
    " # creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"job_title\":job_title[0:10],\"experience_required\":experience_required[0:10],\"company_name\":company_name[0:10],\n",
    "                 \"job_location\":job_location[0:10]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f15a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a89cf19",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes: \n",
    "1. Brand \n",
    "2. Product Description \n",
    "3. Price \n",
    "\n",
    "The attributes which you have to scrape is ticked marked in the below image. \n",
    "To scrape the data you have to go through following steps: \n",
    "    \n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and \n",
    "click the search icon \n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the \n",
    "required data as usual. \n",
    "\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom of the page , then \n",
    "click on it. \n",
    "5. Now scrape data from this page as usual \n",
    "6. Repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "96937821",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementClickInterceptedException",
     "evalue": "Message: element click intercepted: Element <button class=\"L0Z3Pu\" type=\"submit\">...</button> is not clickable at point (556, 28). Other element would receive the click: <div class=\"_2hriZF _2rbIyg\" tabindex=\"-1\">...</div>\n  (Session info: chrome=95.0.4638.69)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x008F0C43+2493507]\n\tOrdinal0 [0x0088A4B1+2073777]\n\tOrdinal0 [0x00792608+1058312]\n\tOrdinal0 [0x007C2B39+1256249]\n\tOrdinal0 [0x007C0E78+1248888]\n\tOrdinal0 [0x007BEC4D+1240141]\n\tOrdinal0 [0x007BDA98+1235608]\n\tOrdinal0 [0x007B3787+1193863]\n\tOrdinal0 [0x007D5943+1333571]\n\tOrdinal0 [0x007B35A6+1193382]\n\tOrdinal0 [0x007D5A2A+1333802]\n\tOrdinal0 [0x007E5038+1396792]\n\tOrdinal0 [0x007D580B+1333259]\n\tOrdinal0 [0x007B2314+1188628]\n\tOrdinal0 [0x007B316F+1192303]\n\tGetHandleVerifier [0x00A77BF6+1548950]\n\tGetHandleVerifier [0x00B2461C+2256060]\n\tGetHandleVerifier [0x0097C13B+518107]\n\tGetHandleVerifier [0x0097B1E0+514176]\n\tOrdinal0 [0x0088F53D+2094397]\n\tOrdinal0 [0x00893418+2110488]\n\tOrdinal0 [0x00893552+2110802]\n\tOrdinal0 [0x0089CE81+2150017]\n\tBaseThreadInitThunk [0x762BFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x76EE7A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x76EE7A6E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-e54da618d0e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#locating the button and clicking it toh search for sunglasses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mbutton\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'L0Z3Pu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mbutton\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mclick\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;34m\"\"\"Clicks the element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLICK_ELEMENT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    420\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m: Message: element click intercepted: Element <button class=\"L0Z3Pu\" type=\"submit\">...</button> is not clickable at point (556, 28). Other element would receive the click: <div class=\"_2hriZF _2rbIyg\" tabindex=\"-1\">...</div>\n  (Session info: chrome=95.0.4638.69)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x008F0C43+2493507]\n\tOrdinal0 [0x0088A4B1+2073777]\n\tOrdinal0 [0x00792608+1058312]\n\tOrdinal0 [0x007C2B39+1256249]\n\tOrdinal0 [0x007C0E78+1248888]\n\tOrdinal0 [0x007BEC4D+1240141]\n\tOrdinal0 [0x007BDA98+1235608]\n\tOrdinal0 [0x007B3787+1193863]\n\tOrdinal0 [0x007D5943+1333571]\n\tOrdinal0 [0x007B35A6+1193382]\n\tOrdinal0 [0x007D5A2A+1333802]\n\tOrdinal0 [0x007E5038+1396792]\n\tOrdinal0 [0x007D580B+1333259]\n\tOrdinal0 [0x007B2314+1188628]\n\tOrdinal0 [0x007B316F+1192303]\n\tGetHandleVerifier [0x00A77BF6+1548950]\n\tGetHandleVerifier [0x00B2461C+2256060]\n\tGetHandleVerifier [0x0097C13B+518107]\n\tGetHandleVerifier [0x0097B1E0+514176]\n\tOrdinal0 [0x0088F53D+2094397]\n\tOrdinal0 [0x00893418+2110488]\n\tOrdinal0 [0x00893552+2110802]\n\tOrdinal0 [0x0089CE81+2150017]\n\tBaseThreadInitThunk [0x762BFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x76EE7A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x76EE7A6E+238]\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the search bar\n",
    "search_bar=driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_bar.send_keys('sunglasses')\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the button and clicking it toh search for sunglasses\n",
    "button=driver.find_element_by_class_name('L0Z3Pu')\n",
    "button.click()\n",
    "\n",
    "\n",
    "#creating the empty list\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "#scrapping the required details\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):#for loop for scrapping 4 page\n",
    "    brands=driver.find_elements_by_class_name('_2WkVRV')#scraping brands name by class name='_2WkVRV'\n",
    "    for i in brands:\n",
    "        brand.append(i.text)#appending the text in Brand list\n",
    "    desc=driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')#scraping description from the xpath\n",
    "    for i in desc:\n",
    "        description.append(i.text)#appending the description in list\n",
    "    prices=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")# scraping the price from the xpath\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ee4cc216",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-1dfc37f6b604>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnxt_button\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m#getting the link from the list for next page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-1dfc37f6b604>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnxt_button\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m#getting the link from the list for next page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnxt_button\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#scrapping all product Url\n",
    "product_url = []\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):#for loop for scrapping 4 page\n",
    "    url=driver.find_elements_by_xpath(\"//a[@class='_2UzuFa']\")\n",
    "    for i in url:\n",
    "        product_url.append(i.get_attribute('href'))\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))     #getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "\n",
    "# scraping discount from each product url\n",
    "for product in product_url:\n",
    "    driver.get(product)\n",
    "    try:\n",
    "        disc=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[3]/div/div[3]/div[1]/div/div[3]/span\")# scraping the discount from the absolute xpath\n",
    "        discount.append(disc.text)\n",
    "    except NoSuchElementException:\n",
    "        discount.append(\"No Discount\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "82ebd372",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-a7fcbbd74e3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#creating a dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m df=pd.DataFrame({'Brand':brand,\n\u001b[0m\u001b[0;32m      3\u001b[0m                 \u001b[1;34m'Description'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                 \u001b[1;34m'Price'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mprice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 })\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         ]\n\u001b[1;32m--> 287\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"arrays must all be same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Brand':brand,\n",
    "                'Description':description,\n",
    "                'Price':price\n",
    "                })\n",
    "#printing dataframe\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bd53ae",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC \n",
    "TSVZAXUHGREPBFGI&marketplace. When you will open the above link you will reach to the below shown webpage . \n",
    "As shown in the above page you have to scrape the tick marked attributes. These are: \n",
    "1. Rating \n",
    "2. Review_summary \n",
    "3. Full review \n",
    "4. You have to scrape this data for first 100 reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c651b9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Stars</th>\n",
       "      <th>Short Review</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>This is my first ever iPhone.\\nAnd I truly don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>The ultimate performance\\nCamera is superb\\nTh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>I use a Note10+ and have been using both iOS a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>The phone is completely good\\nAs far as camera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>3</td>\n",
       "      <td>Decent product</td>\n",
       "      <td>Everything u ll like it when u use this iPhone...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Stars         Short Review  \\\n",
       "0                5            Brilliant   \n",
       "1                5       Simply awesome   \n",
       "2                5     Perfect product!   \n",
       "3                5    Worth every penny   \n",
       "4                5  Best in the market!   \n",
       "..             ...                  ...   \n",
       "85               5               Super!   \n",
       "86               5            Just wow!   \n",
       "87               5    Terrific purchase   \n",
       "88               5              Awesome   \n",
       "89               3       Decent product   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Amazing phone with great cameras and better ba...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   Great iPhone very snappy experience as apple k...  \n",
       "..                                                ...  \n",
       "85  This is my first ever iPhone.\\nAnd I truly don...  \n",
       "86  The ultimate performance\\nCamera is superb\\nTh...  \n",
       "87  I use a Note10+ and have been using both iOS a...  \n",
       "88  The phone is completely good\\nAs far as camera...  \n",
       "89  Everything u ll like it when u use this iPhone...  \n",
       "\n",
       "[90 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# Creating empty list\n",
    "urls=[]\n",
    "short_review=[]\n",
    "complete_review=[]\n",
    "stars=[]\n",
    "time.sleep(2)\n",
    "\n",
    "#scraping 10 pages url\n",
    "url_1 = driver.find_elements_by_xpath(\"//a[@class='ge-49M _2Kfbh8']\")\n",
    "for i in url_1:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "url_2 = driver.find_elements_by_xpath(\"//a[@class='ge-49M']\")\n",
    "for i in url_2:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "time.sleep(4)\n",
    "\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    #for scrapping the number of stars\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\"):\n",
    "        stars.append(j.text)\n",
    "    #for scrapping the short review\n",
    "    for k in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        short_review.append(k.text)\n",
    "    #for scrapping the complete review\n",
    "    for l in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\"):\n",
    "        complete_review.append(l.text)\n",
    "        \n",
    "        \n",
    "        \n",
    "#Combining all the lists into a single dataframe\n",
    "df=pd.DataFrame({'Number of Stars': stars,\n",
    "                'Short Review': short_review,\n",
    "               'Full Review': complete_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2d0922",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the \n",
    "search field. \n",
    "You have to scrape 4 attributes of each sneaker: \n",
    "1. Brand \n",
    "2. Product Description \n",
    "3. Price \n",
    "As shown in the below image, you have to scrape the tick marked attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3b4ba675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rahapta</td>\n",
       "      <td>Sneakers For Men  (Blue)</td>\n",
       "      <td>₹549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rahapta</td>\n",
       "      <td>Mesh Regular &amp; Comfortable Casual Shoes Sneake...</td>\n",
       "      <td>₹549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>LEBRON 2.0 Sneakers For Men  (Navy)</td>\n",
       "      <td>₹479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCATCHITE</td>\n",
       "      <td>Sneakers For Men  (Blue)</td>\n",
       "      <td>₹398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CALCADOS</td>\n",
       "      <td>SM-322 Sneakers For Men  (Navy, Yellow)</td>\n",
       "      <td>₹899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Rahapta</td>\n",
       "      <td>Sneakers For Men  (Yellow)</td>\n",
       "      <td>₹549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Zorth</td>\n",
       "      <td>Luxury Fashionable Breathable Casual Sneakers ...</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tigonis</td>\n",
       "      <td>Sneakers For Men  (White)</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>Stylish &amp; Latest Shoes for Men &amp; Boys Sneakers...</td>\n",
       "      <td>₹762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>SUSON</td>\n",
       "      <td>Sneakers For Men  (Black)</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand                                        Description Price\n",
       "0     Rahapta                           Sneakers For Men  (Blue)  ₹549\n",
       "1     Rahapta  Mesh Regular & Comfortable Casual Shoes Sneake...  ₹549\n",
       "2     Numenzo                LEBRON 2.0 Sneakers For Men  (Navy)  ₹479\n",
       "3   SCATCHITE                           Sneakers For Men  (Blue)  ₹398\n",
       "4    CALCADOS            SM-322 Sneakers For Men  (Navy, Yellow)  ₹899\n",
       "..        ...                                                ...   ...\n",
       "95    Rahapta                         Sneakers For Men  (Yellow)  ₹549\n",
       "96      Zorth  Luxury Fashionable Breathable Casual Sneakers ...  ₹449\n",
       "97    tigonis                          Sneakers For Men  (White)  ₹399\n",
       "98      SPARX  Stylish & Latest Shoes for Men & Boys Sneakers...  ₹762\n",
       "99      SUSON                          Sneakers For Men  (Black)  ₹399\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "#close log_in window\n",
    "log_in_pop_up = driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "log_in_pop_up.click()\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the search bar\n",
    "search_bar=driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_bar.clear()\n",
    "search_bar.send_keys('sneakers')\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the button and clicking it to search for sneakers\n",
    "button=driver.find_element_by_class_name('L0Z3Pu')\n",
    "button.click()\n",
    "\n",
    "\n",
    "#creating the empty list\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "#scrapping the required details\n",
    "start=0\n",
    "end=4\n",
    "for page in range(start,end):#for loop for scrapping 4 page\n",
    "    brands=driver.find_elements_by_class_name('_2WkVRV')#scraping brands name by class name='_2WkVRV'\n",
    "    for i in brands:\n",
    "        brand.append(i.text)#appending the text in Brand list\n",
    "    prices=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")# scraping the price from the xpath\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    disc=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")# scraping the discount from the xpath\n",
    "    for i in disc:\n",
    "        discount.append(i.text)\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "        \n",
    "        \n",
    "time.sleep(2)        \n",
    "# Since in some records not getting description so try from inside of urls\n",
    "urls = []\n",
    "\n",
    "for page in range(0,4):#for loop for scrapping 4 page\n",
    "    \n",
    "    product_url = driver.find_elements_by_xpath(\"//a[@class='_2UzuFa']\")\n",
    "    for i in product_url:\n",
    "        urls.append(i.get_attribute('href'))\n",
    "    \n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "time.sleep(2)        \n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    desc=driver.find_elements_by_xpath('//span[@class=\"B_NuCI\"]')#scraping description from the xpath\n",
    "    for i in desc:\n",
    "        description.append(i.text)#appending the description in list\n",
    "time.sleep(2)        \n",
    "time.sleep(3)        \n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Brand':brand[:100],\n",
    "                'Description':description[:100],\n",
    "                'Price':price[:100]\n",
    "                })\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9200c69e",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes \n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image. \n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe \n",
    "description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7ea2bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the automated webdriver\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "# open link in automated webdriver webpage\n",
    "driver.get(\"https://www.myntra.com/shoes\")\n",
    "\n",
    "# clicking on price filter\n",
    "price_filter = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div')\n",
    "price_filter.click()\n",
    "\n",
    "# clicking on color filter\n",
    "color_filter = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div')\n",
    "color_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bbb06157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "# creating empty list\n",
    "brand = []\n",
    "description = []\n",
    "price = []\n",
    "\n",
    "# setting page limit upto which data needed to be scraped\n",
    "start = 0\n",
    "end = 2\n",
    "\n",
    "#scraping data for brand\n",
    "for page in range(start,end):  # for loop for page\n",
    "    for i in driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]'):\n",
    "        brand.append(i.text)\n",
    "        \n",
    "# scraping data for product description\n",
    "    for i in driver.find_elements_by_xpath('//h4[@class=\"product-product\"]'):\n",
    "        description.append(i.text)\n",
    "        \n",
    "# scraping data for price\n",
    "    for i in driver.find_elements_by_xpath('//div[@class=\"product-price\"]'):\n",
    "        price.append(i.text)\n",
    "        \n",
    "# getting data from next page\n",
    "    nxt_btn = driver.find_elements_by_xpath('//li[@class=\"pagination-next\"]//a')\n",
    "    try:\n",
    "        driver.get(nxt_btn[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(nxt_btn[0].get_attribute('href'))\n",
    "print(len(brand),len(description),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "21dc6cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shoe Brand</th>\n",
       "      <th>Shoe Short Description</th>\n",
       "      <th>Shoe Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H&amp;M</td>\n",
       "      <td>Chunky Combat Boots</td>\n",
       "      <td>Rs. 2699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Bent IDP Sneakers</td>\n",
       "      <td>Rs. 1599Rs. 3999(60% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Street Style Store</td>\n",
       "      <td>Women Suede High-Top Flat Boots</td>\n",
       "      <td>Rs. 1199Rs. 1999(Rs. 800 OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex Kent 2.0 IDP Sneakers</td>\n",
       "      <td>Rs. 1799Rs. 2999(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Campus</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 1529Rs. 1699(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 3849Rs. 5499(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Xtep</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 3279Rs. 4099(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>El Paso</td>\n",
       "      <td>Women High-Top Flat Boots</td>\n",
       "      <td>Rs. 1299Rs. 4799(Rs. 3500 OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Newfeel By Decathlon</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 1699Rs. 1999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men FLIGHT LEGACY Sneakers</td>\n",
       "      <td>Rs. 7995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Shoe Brand           Shoe Short Description  \\\n",
       "0                    H&M              Chunky Combat Boots   \n",
       "1                   Puma            Men Bent IDP Sneakers   \n",
       "2     Street Style Store  Women Suede High-Top Flat Boots   \n",
       "3                   Puma     Unisex Kent 2.0 IDP Sneakers   \n",
       "4                 Campus                Men Running Shoes   \n",
       "..                   ...                              ...   \n",
       "95                  Puma                Men Running Shoes   \n",
       "96                  Xtep                Men Running Shoes   \n",
       "97               El Paso        Women High-Top Flat Boots   \n",
       "98  Newfeel By Decathlon                Men Walking Shoes   \n",
       "99                  Nike       Men FLIGHT LEGACY Sneakers   \n",
       "\n",
       "                        Shoe Price  \n",
       "0                         Rs. 2699  \n",
       "1        Rs. 1599Rs. 3999(60% OFF)  \n",
       "2    Rs. 1199Rs. 1999(Rs. 800 OFF)  \n",
       "3        Rs. 1799Rs. 2999(40% OFF)  \n",
       "4        Rs. 1529Rs. 1699(10% OFF)  \n",
       "..                             ...  \n",
       "95       Rs. 3849Rs. 5499(30% OFF)  \n",
       "96       Rs. 3279Rs. 4099(20% OFF)  \n",
       "97  Rs. 1299Rs. 4799(Rs. 3500 OFF)  \n",
       "98       Rs. 1699Rs. 1999(15% OFF)  \n",
       "99                        Rs. 7995  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating data frame for the data scraped\n",
    "shoe_data = pd.DataFrame({})\n",
    "shoe_data['Shoe Brand'] = brand\n",
    "shoe_data['Shoe Short Description'] = description\n",
    "shoe_data['Shoe Price'] = price\n",
    "shoe_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3d6bb8",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/ \n",
    "Enter “Laptop” in the search field and then click the search icon. \n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image: \n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop: \n",
    "1. Title \n",
    "2. Ratings \n",
    "3. Price \n",
    "As shown in the below image as the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "55e4c6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Pavilion (2021) Intel 11th Gen Core i7 14 i...</td>\n",
       "      <td>84,990</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Envy 11th Gen Intel Core i7 14-inch(35.6 cm...</td>\n",
       "      <td>1,23,190</td>\n",
       "      <td>NO rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP Pavilion (2021) Intel 11th Gen Core i7 14 i...</td>\n",
       "      <td>84,990</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>56,990</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell 14 (2021) i7-1195G7 2in1 Touch Screen Lap...</td>\n",
       "      <td>95,890</td>\n",
       "      <td>4.6 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion x360 (2021) 11th Gen Intel Core i7...</td>\n",
       "      <td>1,00,900</td>\n",
       "      <td>4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo ThinkBook 13s Intel 11th Gen Core i7 13...</td>\n",
       "      <td>85,990</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>93,990</td>\n",
       "      <td>4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...</td>\n",
       "      <td>89,700</td>\n",
       "      <td>3.9 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Pavilion 13(2021) 11th Gen Intel Core i7 13...</td>\n",
       "      <td>89,990</td>\n",
       "      <td>4.6 out of 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Price       Ratings\n",
       "0  HP Pavilion (2021) Intel 11th Gen Core i7 14 i...    84,990  4.3 out of 5\n",
       "1  HP Envy 11th Gen Intel Core i7 14-inch(35.6 cm...  1,23,190     NO rating\n",
       "2  HP Pavilion (2021) Intel 11th Gen Core i7 14 i...    84,990  4.3 out of 5\n",
       "3  Mi Notebook Horizon Edition 14 Intel Core i7-1...    56,990  4.2 out of 5\n",
       "4  Dell 14 (2021) i7-1195G7 2in1 Touch Screen Lap...    95,890  4.6 out of 5\n",
       "5  HP Pavilion x360 (2021) 11th Gen Intel Core i7...  1,00,900    4 out of 5\n",
       "6  Lenovo ThinkBook 13s Intel 11th Gen Core i7 13...    85,990  4.3 out of 5\n",
       "7  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....    93,990    4 out of 5\n",
       "8  Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...    89,700  3.9 out of 5\n",
       "9  HP Pavilion 13(2021) 11th Gen Intel Core i7 13...    89,990  4.6 out of 5"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.amazon.in/ref=nav_logo\"\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "#creating the empty list\n",
    "Title=[]\n",
    "Ratings=[]\n",
    "price=[]\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the search bar\n",
    "search_bar = driver.find_element_by_id(\"twotabsearchtextbox\")    # Locating searc_bar by id\n",
    "search_bar.clear()                                               # clearing search_bar\n",
    "search_bar.send_keys(\"laptops\")                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//span[@id=\"nav-search-submit-text\"]')       # Locating search_button by xpath\n",
    "search_button.click()    \n",
    "\n",
    "time.sleep(2)\n",
    "#locating the core i7 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break\n",
    "        \n",
    "        \n",
    "#Scrapping Titles\n",
    "titles=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in titles[:10]:\n",
    "    Title.append(i.text)\n",
    "    \n",
    "    \n",
    "#scrapping Price\n",
    "prices=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "for i in prices[:10]:\n",
    "    price.append(i.text)\n",
    "\n",
    "#locating Ratings\n",
    "urls=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")#collecting urls of all the laptop\n",
    "UR=[]\n",
    "for i in urls[:10]:\n",
    "    UR.append(i.get_attribute('href'))#getting the url of first 10 laptops\n",
    "for url in UR:#loop for every laptop in the list\n",
    "    driver.get(url)\n",
    "    try:                  #exception handling for nosuchelementexception                                                    #click the rating link found\n",
    "        rating=driver.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']//span\")#locating the rating\n",
    "        Ratings.append(rating.text)#appending the ratings in Ratings list\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        Ratings.append(\"NO rating\")#appending the No rating if no rating is there\n",
    "        \n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Title':Title,\n",
    "                'Price':price,\n",
    "                'Ratings':Ratings})\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bd7818",
   "metadata": {},
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida \n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company. \n",
    "This task will be done in following steps: \n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image \n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter \n",
    "“Data Scientist” and click on search button.\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter \n",
    "“Noida” and select location “Noida”. \n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page. \n",
    "6. Finally create a dataframe of the scraped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "61d34b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"56edd1457ad33850dc27d8273f82c8ba\", element=\"b590d00d-9146-48ef-9681-7462c497abe9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"56edd1457ad33850dc27d8273f82c8ba\", element=\"aecde057-e75b-4267-9d20-2e76113d428d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"56edd1457ad33850dc27d8273f82c8ba\", element=\"a191814e-d2b0-408d-85ee-9eb4d428ab6e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"56edd1457ad33850dc27d8273f82c8ba\", element=\"58adcd44-8ac6-426a-9bc8-f043fd1c0a05\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"56edd1457ad33850dc27d8273f82c8ba\", element=\"196a9bdc-7ada-47b2-a662-a70aa5451a95\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"56edd1457ad33850dc27d8273f82c8ba\", element=\"6c12704e-0cd7-4758-b696-4951f34eaef0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"56edd1457ad33850dc27d8273f82c8ba\", element=\"cc744e88-2b07-46a8-9c30-f33b6f458885\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"56edd1457ad33850dc27d8273f82c8ba\", element=\"0689da9e-d05f-4868-bc35-1e9c5755d956\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"56edd1457ad33850dc27d8273f82c8ba\", element=\"25a8cf8e-f692-41f3-a4a8-11028831829b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"56edd1457ad33850dc27d8273f82c8ba\", element=\"2ad6e29d-d70e-43d0-8a3c-ffa4c70c525b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"56edd1457ad33850dc27d8273f82c8ba\", element=\"0478bc31-c017-46df-b0e6-adccd279b695\")>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick the browser\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "# open url webpage\n",
    "driver.get(\"https://www.ambitionbox.com/jobs/search?tag=data%20science\")\n",
    "\n",
    "# scrape the company info such as name and rating\n",
    "company_info=driver.find_elements_by_xpath(\"//div[@class='company-info']\")\n",
    "\n",
    "# info in the form of wbelement\n",
    "company_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "876cf103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bayer Group\\n · \\n4.4\\nbased on 675 Reviews',\n",
       " 'Bayer Group\\n4.4\\n(675 Reviews)',\n",
       " 'PFIZER LIMITED\\n4.2\\n(1.3k Reviews)',\n",
       " 'AT and T Global Business Services India P. Ltd.\\n4.4\\n(210 Reviews)',\n",
       " 'Novartis Healthcare Pvt. Ltd.\\n4.3\\n(735 Reviews)',\n",
       " 'Intel Technology India Pvt Ltd\\n4.3\\n(261 Reviews)',\n",
       " 'JP Morgan Chase\\n4.1\\n(2.2k Reviews)',\n",
       " 'Amazon Development Centre (India) Pvt. Ltd.\\n4.2\\n(9.1k Reviews)',\n",
       " 'Novartis Healthcare Pvt. Ltd.\\n4.3\\n(735 Reviews)',\n",
       " 'Novartis Healthcare Pvt. Ltd.\\n4.3\\n(735 Reviews)',\n",
       " 'IBM India Pvt. Limited\\n4.1\\n(10.5k Reviews)']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get text from wbelement info and append it into new empty list named \n",
    "company_Info=[]\n",
    "for i in company_info:\n",
    "    company_Info.append(i.text)\n",
    "    \n",
    "# check the list\n",
    "company_Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eb18897f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.4'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# name and rating can be extrat like \n",
    "company_Info[0] #pick 1st item of list\n",
    "\n",
    "company_Info[0].replace('\\n',',') # replace the \\n to ,\n",
    "\n",
    "# make list of name and rating\n",
    "company_Info[0].replace('\\n',',').split(',')\n",
    "\n",
    "# pick name of the company \n",
    "company_Info[0].replace('\\n',',').split(',')[0]\n",
    "\n",
    "# pick the rating of the company\n",
    "company_Info[1].replace('\\n',',').split(',')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a5056960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bayer Group',\n",
       " 'Bayer Group',\n",
       " 'PFIZER LIMITED',\n",
       " 'AT and T Global Business Services India P. Ltd.',\n",
       " 'Novartis Healthcare Pvt. Ltd.',\n",
       " 'Intel Technology India Pvt Ltd',\n",
       " 'JP Morgan Chase',\n",
       " 'Amazon Development Centre (India) Pvt. Ltd.',\n",
       " 'Novartis Healthcare Pvt. Ltd.',\n",
       " 'Novartis Healthcare Pvt. Ltd.']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the company name and rating\n",
    "company_Name=[]\n",
    "company_rating=[]\n",
    "list_n=list(range(0,10))\n",
    "for i in list_n:\n",
    "    company_Name.append(company_Info[i].replace('\\n',',').split(',')[0])\n",
    "    #\n",
    "    company_rating.append(company_Info[i].replace('\\n',',').split(',')[1])\n",
    "    \n",
    "company_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d325c81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' · ', '4.4', '4.2', '4.4', '4.3', '4.3', '4.1', '4.2', '4.3', '4.3']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "99e598ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Company Rating</th>\n",
       "      <th>Days Ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayer Group</td>\n",
       "      <td>·</td>\n",
       "      <td>4d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bayer Group</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2hr ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PFIZER LIMITED</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2hr ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT and T Global Business Services India P. Ltd.</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3hr ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Novartis Healthcare Pvt. Ltd.</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2hr ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Intel Technology India Pvt Ltd</td>\n",
       "      <td>4.3</td>\n",
       "      <td>12hr ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JP Morgan Chase</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amazon Development Centre (India) Pvt. Ltd.</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Novartis Healthcare Pvt. Ltd.</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Novartis Healthcare Pvt. Ltd.</td>\n",
       "      <td>4.3</td>\n",
       "      <td>8hr ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Company Name Company Rating  Days Ago\n",
       "0                                      Bayer Group             ·     4d ago\n",
       "1                                      Bayer Group            4.4   2hr ago\n",
       "2                                   PFIZER LIMITED            4.2   2hr ago\n",
       "3  AT and T Global Business Services India P. Ltd.            4.4   3hr ago\n",
       "4                    Novartis Healthcare Pvt. Ltd.            4.3   2hr ago\n",
       "5                   Intel Technology India Pvt Ltd            4.3  12hr ago\n",
       "6                                  JP Morgan Chase            4.1    4d ago\n",
       "7      Amazon Development Centre (India) Pvt. Ltd.            4.2    4d ago\n",
       "8                    Novartis Healthcare Pvt. Ltd.            4.3    4d ago\n",
       "9                    Novartis Healthcare Pvt. Ltd.            4.3   8hr ago"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acvertisements have posted for how many days\n",
    "days_ago=[]\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='body-small-l']\"):\n",
    "    # class='body-small-l' attribute is related to two info time and publisher\n",
    "    days_ago.append(i.text)\n",
    "    \n",
    "# class='body-small-l' attribute is related to two info time and publisher\n",
    "days_ago\n",
    "\n",
    "Days_ago=days_ago[0:20:2]\n",
    "\n",
    "# list of acvertisements have posted for how many days.\n",
    "Days_ago\n",
    "\n",
    "# create dataframe from scraped data\n",
    "job=pd.DataFrame()\n",
    "job['Company Name']=company_Name\n",
    "job['Company Rating']=company_rating\n",
    "job['Days Ago']=Days_ago\n",
    "\n",
    "job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26714c4",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation. \n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary. \n",
    "The above task will be, done as shown in the below steps: \n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image. \n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and \n",
    "then click on “Data Scientist”. \n",
    "You have to scrape the data ticked in the above image. \n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average \n",
    "salary, minimum salary, maximum salary, experience required. \n",
    "5. Store the data in a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cb2b357a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"d5c39d7334cc742d9dfa567139f3d417\", element=\"12230e0d-65e5-43b0-8edf-42fbe990a082\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d5c39d7334cc742d9dfa567139f3d417\", element=\"0be5940f-7f7c-4f23-9865-a0a76a28610a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d5c39d7334cc742d9dfa567139f3d417\", element=\"0ab5f5e2-5e4e-44b6-80c1-08dd208d0b9e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d5c39d7334cc742d9dfa567139f3d417\", element=\"bd21ad21-3e6c-484d-b541-03605c7aa398\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d5c39d7334cc742d9dfa567139f3d417\", element=\"8c423f96-d762-4f0d-94c2-6b7867af0ae0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d5c39d7334cc742d9dfa567139f3d417\", element=\"17f710f7-8b2e-47ef-9c13-48f33490b599\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d5c39d7334cc742d9dfa567139f3d417\", element=\"7140d44f-13e8-448f-8740-06b32ad59b4b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d5c39d7334cc742d9dfa567139f3d417\", element=\"32e7265a-9369-47d9-b186-9766718a20ba\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d5c39d7334cc742d9dfa567139f3d417\", element=\"3b8149ce-db34-47a0-bcce-880f8ff0a073\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"d5c39d7334cc742d9dfa567139f3d417\", element=\"008667e0-d6dd-4036-bcb3-df90fc6372b3\")>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open browser\n",
    "driver=webdriver.Chrome()\n",
    "# open url webpage\n",
    "url=\"https://www.ambitionbox.com/profile/data-scientist-salary\"\n",
    "driver.get(url)\n",
    "# get the div tag in which name and salary info is givern\n",
    "div=driver.find_elements_by_xpath(\"//div[@class='name']\")\n",
    "div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8642f929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capgemini\n",
      "(220 Salaries)\n"
     ]
    }
   ],
   "source": [
    "# div tag consist of company name and salary info\n",
    "div[0].text\n",
    "\n",
    "# replace \\n into ,\n",
    "div[0].text.replace('\\n',',')\n",
    "\n",
    "# split the string\n",
    "div[0].text.replace('\\n',',').split(',')\n",
    "\n",
    "# get the name of company\n",
    "# div[i].text.replace('\\n',',').split(',')[j]\n",
    "# different i gives different company name \n",
    "# range of j is two for j=0 it gives company name and for j=1 get salary count\n",
    "print(div[4].text.replace('\\n',',').split(',')[0])\n",
    "print(div[4].text.replace('\\n',',').split(',')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a401fd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TCS',\n",
       " 'Accenture',\n",
       " 'IBM',\n",
       " 'Cognizant',\n",
       " 'Capgemini',\n",
       " 'Tech Mahindra',\n",
       " 'Infosys',\n",
       " 'Wipro',\n",
       " 'Ericsson',\n",
       " 'HCL Technologies']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make list of name and salary info\n",
    "name=[]\n",
    "salary_count=[]\n",
    "list_n=list(range(0,10))\n",
    "for i in list_n:\n",
    "    name.append(div[i].text.replace('\\n',',').split(',')[0])\n",
    "    salary_count.append(div[i].text.replace('\\n',',').split(',')[1])\n",
    "    \n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f32bcaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(594 Salaries)',\n",
       " '(355 Salaries)',\n",
       " '(289 Salaries)',\n",
       " '(233 Salaries)',\n",
       " '(220 Salaries)',\n",
       " '(182 Salaries)',\n",
       " '(166 Salaries)',\n",
       " '(164 Salaries)',\n",
       " '(123 Salaries)',\n",
       " '(116 Salaries)']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "88c3438c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2-9 yrs exp',\n",
       " '2-9 yrs exp',\n",
       " '2-12 yrs exp',\n",
       " '2-11 yrs exp',\n",
       " '2-8 yrs exp',\n",
       " '2-13 yrs exp',\n",
       " '2-8 yrs exp',\n",
       " '2-9 yrs exp',\n",
       " '2-12 yrs exp',\n",
       " '2-10 yrs exp']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the div tag for experience data scraping\n",
    "div2=driver.find_elements_by_xpath(\"//div[@class='salaries one-line sbold-list-header']\")\n",
    "# make the list of experience required\n",
    "experience_req=[]\n",
    "for i in div2:\n",
    "    experience_req.append(i.text)\n",
    "experience_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "259f3955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 7.3L\\n₹ 4.4L\\n₹ 15.0L',\n",
       " '₹ 11.7L\\n₹ 5.4L\\n₹ 22.0L',\n",
       " '₹ 11.6L\\n₹ 5.0L\\n₹ 22.5L',\n",
       " '₹ 9.4L\\n₹ 4.9L\\n₹ 17.0L',\n",
       " '₹ 8.2L\\n₹ 4.6L\\n₹ 14.3L',\n",
       " '₹ 7.7L\\n₹ 4.2L\\n₹ 16.4L',\n",
       " '₹ 8.7L\\n₹ 4.5L\\n₹ 25.0L',\n",
       " '₹ 9.2L\\n₹ 4.3L\\n₹ 18.0L',\n",
       " '₹ 12.9L\\n₹ 5.0L\\n₹ 25.0L',\n",
       " '₹ 9.0L\\n₹ 4.5L\\n₹ 19.0L']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the data about salary range\n",
    "salary_range=[]\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='result-col salary-range']\"):\n",
    "    salary_range.append(i.text)\n",
    "salary_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7f9ce398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['₹ 4.4L', '₹ 5.4L', '₹ 5.0L', '₹ 4.9L', '₹ 4.6L', '₹ 4.2L', '₹ 4.5L', '₹ 4.3L', '₹ 5.0L', '₹ 4.5L']\n",
      "['₹ 7.3L', '₹ 11.7L', '₹ 11.6L', '₹ 9.4L', '₹ 8.2L', '₹ 7.7L', '₹ 8.7L', '₹ 9.2L', '₹ 12.9L', '₹ 9.0L']\n",
      "['₹ 15.0L', '₹ 22.0L', '₹ 22.5L', '₹ 17.0L', '₹ 14.3L', '₹ 16.4L', '₹ 25.0L', '₹ 18.0L', '₹ 25.0L', '₹ 19.0L']\n"
     ]
    }
   ],
   "source": [
    "# scrap minimum, average, and maximum salary\n",
    "min_salary=[]\n",
    "average_salary=[]\n",
    "max_salary=[]\n",
    "for i in list_n:\n",
    "    min_salary.append(salary_range[i].replace('\\n',',').split(',')[1])\n",
    "    average_salary.append(salary_range[i].replace('\\n',',').split(',')[0])\n",
    "    max_salary.append(salary_range[i].replace('\\n',',').split(',')[2])\n",
    "print(min_salary)\n",
    "print(average_salary)\n",
    "print(max_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dcc45743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company Name</th>\n",
       "      <th>salary count</th>\n",
       "      <th>experience required</th>\n",
       "      <th>minimum salary</th>\n",
       "      <th>average salary</th>\n",
       "      <th>maximum salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCS</td>\n",
       "      <td>(594 Salaries)</td>\n",
       "      <td>2-9 yrs exp</td>\n",
       "      <td>₹ 4.4L</td>\n",
       "      <td>₹ 7.3L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>(355 Salaries)</td>\n",
       "      <td>2-9 yrs exp</td>\n",
       "      <td>₹ 5.4L</td>\n",
       "      <td>₹ 11.7L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>(289 Salaries)</td>\n",
       "      <td>2-12 yrs exp</td>\n",
       "      <td>₹ 5.0L</td>\n",
       "      <td>₹ 11.6L</td>\n",
       "      <td>₹ 22.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cognizant</td>\n",
       "      <td>(233 Salaries)</td>\n",
       "      <td>2-11 yrs exp</td>\n",
       "      <td>₹ 4.9L</td>\n",
       "      <td>₹ 9.4L</td>\n",
       "      <td>₹ 17.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Capgemini</td>\n",
       "      <td>(220 Salaries)</td>\n",
       "      <td>2-8 yrs exp</td>\n",
       "      <td>₹ 4.6L</td>\n",
       "      <td>₹ 8.2L</td>\n",
       "      <td>₹ 14.3L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>(182 Salaries)</td>\n",
       "      <td>2-13 yrs exp</td>\n",
       "      <td>₹ 4.2L</td>\n",
       "      <td>₹ 7.7L</td>\n",
       "      <td>₹ 16.4L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>(166 Salaries)</td>\n",
       "      <td>2-8 yrs exp</td>\n",
       "      <td>₹ 4.5L</td>\n",
       "      <td>₹ 8.7L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wipro</td>\n",
       "      <td>(164 Salaries)</td>\n",
       "      <td>2-9 yrs exp</td>\n",
       "      <td>₹ 4.3L</td>\n",
       "      <td>₹ 9.2L</td>\n",
       "      <td>₹ 18.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>(123 Salaries)</td>\n",
       "      <td>2-12 yrs exp</td>\n",
       "      <td>₹ 5.0L</td>\n",
       "      <td>₹ 12.9L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>(116 Salaries)</td>\n",
       "      <td>2-10 yrs exp</td>\n",
       "      <td>₹ 4.5L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 19.0L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       company Name    salary count experience required minimum salary  \\\n",
       "0               TCS  (594 Salaries)         2-9 yrs exp         ₹ 4.4L   \n",
       "1         Accenture  (355 Salaries)         2-9 yrs exp         ₹ 5.4L   \n",
       "2               IBM  (289 Salaries)        2-12 yrs exp         ₹ 5.0L   \n",
       "3         Cognizant  (233 Salaries)        2-11 yrs exp         ₹ 4.9L   \n",
       "4         Capgemini  (220 Salaries)         2-8 yrs exp         ₹ 4.6L   \n",
       "5     Tech Mahindra  (182 Salaries)        2-13 yrs exp         ₹ 4.2L   \n",
       "6           Infosys  (166 Salaries)         2-8 yrs exp         ₹ 4.5L   \n",
       "7             Wipro  (164 Salaries)         2-9 yrs exp         ₹ 4.3L   \n",
       "8          Ericsson  (123 Salaries)        2-12 yrs exp         ₹ 5.0L   \n",
       "9  HCL Technologies  (116 Salaries)        2-10 yrs exp         ₹ 4.5L   \n",
       "\n",
       "  average salary maximum salary  \n",
       "0         ₹ 7.3L        ₹ 15.0L  \n",
       "1        ₹ 11.7L        ₹ 22.0L  \n",
       "2        ₹ 11.6L        ₹ 22.5L  \n",
       "3         ₹ 9.4L        ₹ 17.0L  \n",
       "4         ₹ 8.2L        ₹ 14.3L  \n",
       "5         ₹ 7.7L        ₹ 16.4L  \n",
       "6         ₹ 8.7L        ₹ 25.0L  \n",
       "7         ₹ 9.2L        ₹ 18.0L  \n",
       "8        ₹ 12.9L        ₹ 25.0L  \n",
       "9         ₹ 9.0L        ₹ 19.0L  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe from scraped data\n",
    "job_info=pd.DataFrame()\n",
    "job_info['company Name']=name\n",
    "job_info['salary count']=salary_count\n",
    "job_info['experience required']=experience_req\n",
    "job_info['minimum salary']=min_salary\n",
    "job_info['average salary']=average_salary\n",
    "job_info['maximum salary']=max_salary\n",
    "# show the dataframe\n",
    "job_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618bed67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
